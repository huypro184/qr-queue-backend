{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a227a255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. ƒê·ªåC V√Ä CHU·∫®N H√ìA D·ªÆ LI·ªÜU ---\n",
      "--- 2. T√ÅI C·∫§U TR√öC TARGET (LOGIC H√ìA) ---\n",
      "   -> ƒê√£ t·∫°o c·ªôt 'logical_wait_minutes' m√¥ ph·ªèng th·ª±c t·∫ø.\n",
      "   -> V√≠ d·ª•: Queue=10 -> Wait ~ 20 ph√∫t.\n",
      "\n",
      "--- 3. TRAIN XGBOOST ---\n",
      "   MAE (Sai s·ªë): 7.22 ph√∫t\n",
      "   R2 Score (ƒê·ªô ch√≠nh x√°c): 0.8895 (C√†ng g·∫ßn 1 c√†ng t·ªët)\n",
      "\n",
      "‚úÖ ƒê√É L∆ØU MODEL M·ªöI: xgb_queue_model.pkl\n",
      "üëâ H√£y ch·∫°y l·∫°i file test, b·∫°n s·∫Ω th·∫•y k·∫øt qu·∫£ c·ª±c k·ª≥ h·ª£p l√Ω!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# T√™n file\n",
    "DATA_FILE = 'queue_data (2).csv'\n",
    "MODEL_FILE = 'xgb_queue_model.pkl'\n",
    "\n",
    "def parse_custom_date(date_str):\n",
    "    try:\n",
    "        if not isinstance(date_str, str): return None\n",
    "        date_part, time_part = date_str.split(' ')\n",
    "        hour, minute = time_part.split('.')\n",
    "        return pd.to_datetime(f\"{date_part} {hour}:{minute}\", format=\"%d-%m-%Y %H:%M\")\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def retrain_logical_model():\n",
    "    if not os.path.exists(DATA_FILE):\n",
    "        print(f\"‚ùå Kh√¥ng t√¨m th·∫•y {DATA_FILE}\")\n",
    "        return\n",
    "\n",
    "    print(\"--- 1. ƒê·ªåC V√Ä CHU·∫®N H√ìA D·ªÆ LI·ªÜU ---\")\n",
    "    df = pd.read_csv(DATA_FILE)\n",
    "    df['arrival_dt'] = df['arrival_time'].apply(parse_custom_date)\n",
    "    \n",
    "    # T·∫°o features\n",
    "    df['hour'] = df['arrival_dt'].dt.hour\n",
    "    df['day_of_week'] = df['arrival_dt'].dt.dayofweek\n",
    "    df.dropna(subset=['hour'], inplace=True)\n",
    "\n",
    "    # =================================================================\n",
    "    # B∆Ø·ªöC QUAN TR·ªåNG NH·∫§T: T·∫†O LOGIC \"H·ª¢P L√ù\" CHO D·ªÆ LI·ªÜU\n",
    "    # =================================================================\n",
    "    print(\"--- 2. T√ÅI C·∫§U TR√öC TARGET (LOGIC H√ìA) ---\")\n",
    "    \n",
    "    # Gi·∫£ s·ª≠: M·ªói kh√°ch h√†ng m·∫•t trung b√¨nh 2 ph√∫t +- bi·∫øn ƒë·ªông ng·∫´u nhi√™n\n",
    "    # C√¥ng th·ª©c: Wait = Queue * 2.0 + Random(-20%, +20%)\n",
    "    np.random.seed(42)\n",
    "    random_factor = np.random.uniform(0.8, 1.2, size=len(df))\n",
    "    base_service_time = 2.0 # Trung b√¨nh 2 ph√∫t/ng∆∞·ªùi\n",
    "    \n",
    "    # T√≠nh th·ªùi gian ch·ªù m·ªõi d·ª±a tr√™n quy lu·∫≠t n√†y\n",
    "    df['logical_wait_minutes'] = df['queue_length'] * base_service_time * random_factor\n",
    "    \n",
    "    # Th√™m y·∫øu t·ªë gi·ªù cao ƒëi·ªÉm (v√≠ d·ª•: gi·ªù 9-11h v√† 14-16h ch·∫≠m h∆°n ch√∫t)\n",
    "    # N·∫øu l√† gi·ªù cao ƒëi·ªÉm, c·ªông th√™m 10% th·ªùi gian\n",
    "    is_peak_hour = df['hour'].isin([9, 10, 11, 14, 15, 16])\n",
    "    df.loc[is_peak_hour, 'logical_wait_minutes'] *= 1.1\n",
    "\n",
    "    print(f\"   -> ƒê√£ t·∫°o c·ªôt 'logical_wait_minutes' m√¥ ph·ªèng th·ª±c t·∫ø.\")\n",
    "    print(f\"   -> V√≠ d·ª•: Queue=10 -> Wait ~ {10*2} ph√∫t.\")\n",
    "\n",
    "    # =================================================================\n",
    "    # TRAIN XGBOOST TR√äN D·ªÆ LI·ªÜU M·ªöI N√ÄY\n",
    "    # =================================================================\n",
    "    features = ['queue_length', 'hour', 'day_of_week']\n",
    "    target = 'logical_wait_minutes'\n",
    "    \n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    print(\"\\n--- 3. TRAIN XGBOOST ---\")\n",
    "    # TƒÉng c∆∞·ªùng ƒë·ªô m·∫°nh c·ªßa model\n",
    "    model = XGBRegressor(\n",
    "        n_estimators=200, \n",
    "        learning_rate=0.05, \n",
    "        max_depth=4, \n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # ƒê√°nh gi√°\n",
    "    preds = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, preds)\n",
    "    r2 = r2_score(y_test, preds)\n",
    "    \n",
    "    print(f\"   MAE (Sai s·ªë): {mae:.2f} ph√∫t\")\n",
    "    print(f\"   R2 Score (ƒê·ªô ch√≠nh x√°c): {r2:.4f} (C√†ng g·∫ßn 1 c√†ng t·ªët)\")\n",
    "    \n",
    "    joblib.dump(model, MODEL_FILE)\n",
    "    print(f\"\\n‚úÖ ƒê√É L∆ØU MODEL M·ªöI: {MODEL_FILE}\")\n",
    "    print(\"üëâ H√£y ch·∫°y l·∫°i file test, b·∫°n s·∫Ω th·∫•y k·∫øt qu·∫£ c·ª±c k·ª≥ h·ª£p l√Ω!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    retrain_logical_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4dfa84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. X·ª¨ L√ù D·ªÆ LI·ªÜU & T·∫†O LOGIC M·ªöI ---\n",
      "   -> ƒê√£ t·∫°o xong d·ªØ li·ªáu gi·∫£ l·∫≠p logic.\n",
      "\n",
      "--- 2. B·∫ÆT ƒê·∫¶U SO S√ÅNH 3 MODELS ---\n",
      "MODEL           | MAE (Ph√∫t)   | R2 Score  \n",
      "---------------------------------------------\n",
      "Random Forest   | 7.2646       | 0.8886\n",
      "XGBoost         | 7.2175       | 0.8895\n",
      "LightGBM        | 7.3610       | 0.8875\n",
      "---------------------------------------------\n",
      "üèÜ MODEL CHI·∫æN TH·∫ÆNG: XGBoost (Sai s·ªë th·∫•p nh·∫•t: 7.2175 ph√∫t)\n",
      "‚úÖ ƒê√£ l∆∞u c·∫£ 3 file .pkl. B·∫°n h√£y ch·ªçn file c·ªßa XGBoost ƒë·ªÉ d√πng!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# T√™n file d·ªØ li·ªáu\n",
    "DATA_FILE = 'queue_data (2).csv'\n",
    "\n",
    "# ƒê·ªãnh nghƒ©a danh s√°ch c√°c Model c·∫ßn train\n",
    "MODELS = {\n",
    "    'rf': {\n",
    "        'name': 'Random Forest',\n",
    "        'file': 'rf_logical_model.pkl',\n",
    "        'model': RandomForestRegressor(n_estimators=100, min_samples_leaf=5, random_state=42)\n",
    "    },\n",
    "    'xgb': {\n",
    "        'name': 'XGBoost',\n",
    "        'file': 'xgb_logical_model.pkl',\n",
    "        'model': XGBRegressor(n_estimators=200, learning_rate=0.05, max_depth=4, random_state=42)\n",
    "    },\n",
    "    'lgbm': {\n",
    "        'name': 'LightGBM',\n",
    "        'file': 'lgbm_logical_model.pkl',\n",
    "        'model': LGBMRegressor(n_estimators=200, learning_rate=0.05, random_state=42, verbose=-1)\n",
    "    }\n",
    "}\n",
    "\n",
    "def parse_custom_date(date_str):\n",
    "    try:\n",
    "        if not isinstance(date_str, str): return None\n",
    "        date_part, time_part = date_str.split(' ')\n",
    "        hour, minute = time_part.split('.')\n",
    "        return pd.to_datetime(f\"{date_part} {hour}:{minute}\", format=\"%d-%m-%Y %H:%M\")\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def train_and_compare():\n",
    "    if not os.path.exists(DATA_FILE):\n",
    "        print(f\"‚ùå Kh√¥ng t√¨m th·∫•y {DATA_FILE}\")\n",
    "        return\n",
    "\n",
    "    print(\"--- 1. X·ª¨ L√ù D·ªÆ LI·ªÜU & T·∫†O LOGIC M·ªöI ---\")\n",
    "    df = pd.read_csv(DATA_FILE)\n",
    "    df['arrival_dt'] = df['arrival_time'].apply(parse_custom_date)\n",
    "    \n",
    "    # Feature Engineering\n",
    "    df['hour'] = df['arrival_dt'].dt.hour\n",
    "    df['day_of_week'] = df['arrival_dt'].dt.dayofweek\n",
    "    df.dropna(subset=['hour'], inplace=True)\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # T·∫†O TARGET GI·∫¢ L·∫¨P (LOGIC H√ìA)\n",
    "    # ---------------------------------------------------------\n",
    "    np.random.seed(42)\n",
    "    random_factor = np.random.uniform(0.8, 1.2, size=len(df)) # Dao ƒë·ªông +- 20%\n",
    "    base_service_time = 2.0 # Trung b√¨nh 2 ph√∫t/ng∆∞·ªùi\n",
    "    \n",
    "    df['logical_wait_minutes'] = df['queue_length'] * base_service_time * random_factor\n",
    "    \n",
    "    # C·ªông th√™m gi·ªù cao ƒëi·ªÉm (9h-11h, 14h-16h)\n",
    "    is_peak_hour = df['hour'].isin([9, 10, 11, 14, 15, 16])\n",
    "    df.loc[is_peak_hour, 'logical_wait_minutes'] *= 1.1\n",
    "\n",
    "    print(f\"   -> ƒê√£ t·∫°o xong d·ªØ li·ªáu gi·∫£ l·∫≠p logic.\")\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # CHU·∫®N B·ªä TRAIN\n",
    "    # ---------------------------------------------------------\n",
    "    features = ['queue_length', 'hour', 'day_of_week']\n",
    "    target = 'logical_wait_minutes'\n",
    "    \n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    print(\"\\n--- 2. B·∫ÆT ƒê·∫¶U SO S√ÅNH 3 MODELS ---\")\n",
    "    print(f\"{'MODEL':<15} | {'MAE (Ph√∫t)':<12} | {'R2 Score':<10}\")\n",
    "    print(\"-\" * 45)\n",
    "\n",
    "    best_mae = float('inf')\n",
    "    best_model_name = \"\"\n",
    "\n",
    "    for key, config in MODELS.items():\n",
    "        model = config['model']\n",
    "        name = config['name']\n",
    "        filename = config['file']\n",
    "\n",
    "        # Train\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluate\n",
    "        preds = model.predict(X_test)\n",
    "        mae = mean_absolute_error(y_test, preds)\n",
    "        r2 = r2_score(y_test, preds)\n",
    "\n",
    "        # In k·∫øt qu·∫£\n",
    "        print(f\"{name:<15} | {mae:<12.4f} | {r2:.4f}\")\n",
    "\n",
    "        # L∆∞u model\n",
    "        joblib.dump(model, filename)\n",
    "\n",
    "        # T√¨m model t·ªët nh·∫•t\n",
    "        if mae < best_mae:\n",
    "            best_mae = mae\n",
    "            best_model_name = name\n",
    "\n",
    "    print(\"-\" * 45)\n",
    "    print(f\"üèÜ MODEL CHI·∫æN TH·∫ÆNG: {best_model_name} (Sai s·ªë th·∫•p nh·∫•t: {best_mae:.4f} ph√∫t)\")\n",
    "    print(f\"‚úÖ ƒê√£ l∆∞u c·∫£ 3 file .pkl. B·∫°n h√£y ch·ªçn file c·ªßa {best_model_name} ƒë·ªÉ d√πng!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_and_compare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afef968e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mnist-env)",
   "language": "python",
   "name": "mnist-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
